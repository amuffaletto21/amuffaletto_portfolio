<html>
<body style=background-color:rgb(156, 238, 206)>
<head>
  <style>
  h1 {
    font-family: courier;
    color:rgb(107, 216, 231);
    text-align: center

  }
  div {
    display: flex;
    flex-direction: column;
    padding:15px;
    margin: 0 auto;
    border: 5px solid#69e9d2;
    border-radius: 5px;
    font-family:arial;
    color:rgb(123, 0, 138);
    background-color:rgb(203, 195, 233);
  }
  </style>
</head>
  <h1>Ethical Reflections </h1>
  <div class="machine">
    <h2>Ethical Reflection #1: Machine Bias</h2>
    <p>People everywhere are being wrongfully imprisoned everyday. While this may attribute to a false testimony from witnesses in court, or a misunderstanding, another probable cause for these incorrect arrests are biased algorithms. In many states around the country, these biased algorithms are the reason for illegitimate confinement, such as Wisconsin and Ohio. One of the algorithms that are used to determine how long someone should stay in custody for is called COMPAS (Correctional Offender Management Profiling for Alternative Sanctions). COMPAS has around 100 questions that are about quality of life, prior issues with the law, and much more that give courts more information about how long someone should stay in prison for and if they qualify for parole in the future, it indicates what type of help the parolee will need. This all seems great in theory, however, the system is flawed because it has a bias: against black people. In an article by<a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">ProPublica </a>, they covered the general facts of this issue, and in an article by <a href="https://www.technologyreview.com/s/607955/inspecting-algorithms-for-bias/MIT"> Technology Review</a>, they talked more about the issue and explained how and why the algorithms are biased by clarifying the system of “true positives.” True positives aren’t exactly used just to discover the high risk offenders, but also to find the most of these “high risk” repeat offenders. After reading both of these articles, this further solidifies my disappointment in this country and the way that it handles issues of race. These types of issues are hardly talked about in general in the media, even though this has such a huge impact on communities around the country and even the world. These types of algorithms shouldn’t be used to assess how many years a person should spend in prison and whether or not they will commit more crimes. Since the questions that are part of the algorithm are generic and only scrape the surface of a person’s life and can apply to most people of a certain group, they really should have no value in these types of decisions. Every person has a unique life story, and the details should be evaluated more heavily than simply the generalities of their situation. I believe that the system is inherently flawed already, even without the bias that the algorithms have, because the place that someone was raised, the type of people they hang out with, and most of all their race, should have no place in a decision of whether or not they should be arrested.
    </p>

    <h2>Ethical Reflection #2: </h2>
    <h2>Ethical Reflection #3: </h2>
    <h2>Ethical Reflection #4: </h2>
    <h2>Ethical Reflection #5: </h2>
  </div>



</body>
</html>
